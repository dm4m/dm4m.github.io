
@article{zhang_neural_2021,
	title = {Neural {Time}-{Aware} {Sequential} {Recommendation} by {Jointly} {Modeling} {Preference} {Dynamics} and {Explicit} {Feature} {Couplings}},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2021.3069058},
	abstract = {In recommendation, both stationary and dynamic user preferences on items are embedded in the interactions between users and items (e.g., rating or clicking) within their contexts. Sequential recommender systems (SRSs) need to jointly involve such context-aware user-item interactions in terms of the couplings between the user and item features and sequential user actions on items over time. However, such joint modeling is non-trivial and significantly challenges the existing work on preference modeling, which either only models user-item interactions by latent factorization models but ignores user preference dynamics or only captures sequential user action patterns without involving user/item features and context factors and their coupling and influence on user actions. We propose a neural time-aware recommendation network (TARN) with a temporal context to jointly model 1) stationary user preferences by a feature interaction network and 2) user preference dynamics by a tailored convolutional network. The feature interaction network factorizes the pairwise couplings between non-zero features of users, items, and temporal context by the inner product of their feature embeddings while alleviating data sparsity issues. In the convolutional network, we introduce a convolutional layer with multiple filter widths to capture multi-fold sequential patterns, where an attentive average pooling (AAP) obtains significant and large-span feature combinations. To learn the preference dynamics, a novel temporal action embedding represents user actions by incorporating the embeddings of items and temporal context as the inputs of the convolutional network. The experiments on typical public data sets demonstrate that TARN outperforms state-of-the-art methods and show the necessity and contribution of involving time-aware preference dynamics and explicit user/item feature couplings in modeling and interpreting evolving user preferences.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Zhang, Qi and Cao, Longbing and Shi, Chongyang and Niu, Zhendong},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Computational modeling, Context modeling, Convolutional neural network (CNN), coupling learning, Couplings, Data models, explicit features, feature couplings, Feature extraction, Markov processes, Motion pictures, recommender system, sequential recommendation, time-aware sequential recommendation, user preference dynamics.},
	pages = {1--13},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\64850\\Zotero\\storage\\6RRZGK82\\9404857.html:text/html},
}

@article{zhang_tripartite_2021,
	title = {Tripartite {Collaborative} {Filtering} with {Observability} and {Selection} for {Debiasing} {Rating} {Estimation} on {Missing}-{Not}-at-{Random} {Data}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16597},
	abstract = {Most collaborative filtering (CF) models estimate missing ratings with an implicit assumption that the ratings are missing-at-random, which may cause the biased rating estimation and degraded performance since recent deep exploration shows that ratings may likely be missing-not-at-random (MNAR). To debias MNAR rating estimation, we introduce item observability and user selection to depict the generation of MNAR ratings and propose a tripartite CF (TCF) framework to jointly model the triple aspects of rating generation: item observability, user selection, and ratings, and to estimate the MNAR ratings. An item observability variable is introduced to a complete observability model to infer whether an item is observable to a user. TCF also conducts a complete rating model for rating generation and utilizes a user selection model dependent on the item observability and rating values to model user selection of the observable items. We further elaborately instantiate TCF as a Tripartite Probabilistic Matrix Factorization model (TPMF) by leveraging the probabilistic matrix factorization. Besides, TPMF introduces multifaceted dependency between user selection and ratings to model the influence of user selection on ratings. Extensive experiments on synthetic and real-world datasets show that modeling item observability and user selection effectively debias MNAR rating estimation, and TPMF outperforms the state-of-the-art methods in estimating the MNAR ratings.},
	language = {en},
	number = {5},
	urldate = {2022-01-22},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Zhang, Qi and Cao, Longbing and Shi, Chongyang and Hu, Liang},
	month = may,
	year = {2021},
	note = {Number: 5},
	keywords = {Recommender Systems \& Collaborative Filtering},
	pages = {4671--4678},
	file = {Full Text PDF:C\:\\Users\\64850\\Zotero\\storage\\9HN46IQX\\Zhang 等。 - 2021 - Tripartite Collaborative Filtering with Observabil.pdf:application/pdf},
}

@incollection{guo_intention_2020,
	address = {New York, NY, USA},
	title = {Intention {Modeling} from {Ordered} and {Unordered} {Facets} for {Sequential} {Recommendation}},
	isbn = {978-1-4503-7023-3},
	url = {https://doi.org/10.1145/3366423.3380190},
	abstract = {Recently, sequential recommendation has attracted substantial attention from researchers due to its status as an essential service for e-commerce. Accurately understanding user intention is an important factor to improve the performance of recommendation system. However, user intention is highly time-dependent and flexible, so it is very challenging to learn the latent dynamic intention of users for sequential recommendation. To this end, in this paper, we propose a novel intention modeling from ordered and unordered facets (IMfOU) for sequential recommendation. Specifically, the global and local item embedding (GLIE) we proposed can comprehensively capture the sequential context information in the sequences and highlight the important features that users care about. We further design ordered preference drift learning (OPDL) and unordered purchase motivation learning (UPML) to obtain user’s the process of preference drift and purchase motivation respectively. With combining the users’ dynamic preference and current motivation, it considers not only sequential dependencies between items but also flexible dependencies and models the user purchase intention more accurately from ordered and unordered facets respectively. Evaluation results on three real-world datasets demonstrate that our proposed approach achieves better performance than the state-of-the-art sequential recommendation methods achieving improvement of AUC by an average of 2.26\%.},
	urldate = {2022-01-21},
	booktitle = {Proceedings of {The} {Web} {Conference} 2020},
	publisher = {Association for Computing Machinery},
	author = {Guo, Xueliang and Shi, Chongyang and Liu, Chuanming},
	month = apr,
	year = {2020},
	keywords = {preference drift, purchased motivation, sequential recommendation, user intention},
	pages = {1127--1137},
}

@incollection{lao_rumor_2021,
	address = {New York, NY, USA},
	title = {Rumor {Detection} with {Field} of {Linear} and {Non}-{Linear} {Propagation}},
	isbn = {978-1-4503-8312-7},
	url = {https://doi.org/10.1145/3442381.3450016},
	abstract = {The propagation of rumors is a complex and varied phenomenon. In the process of rumor dissemination, in addition to rumor claims, there will be abundant social context information surrounding the rumor. Therefore, it is vital to learn the characteristics of rumors in terms of both the linear temporal sequence and the non-linear diffusion structure simultaneously. However, in some existing research, time-dependent and diffusion-related information has not been fully utilized. Accordingly, in this paper, we propose a novel model Rumor Detection with Field of Linear and Non-Linear Propagation (RDLNP) to automatically detect rumors from the above two fields by taking advantage of claim content, social context and temporal information. First, the Rumor Hybrid Feature Learning (RHFL) we designed can extract the correlations between the claims and temporal information, differentiate the hybrid features of specific posts, and generate unified representations for rumors. Second, we proposed Non-Linear Structure Learning (NLSL) and Linear Sequence Learning (LSL) to integrate contextual features along the path of the diffusion structure and temporal engagement variation of responses respectively. Finally, Shared Feature Learning (SFL) models the representation reinforcement and learns the mutual influence between NLSL and LSL, and then highlights their valuable features. Experiments conduct on two public and widely used datasets, i.e. PHEME and RumorEval, demonstrate both the effectiveness and the outstanding performance of the proposed approach.},
	urldate = {2022-01-21},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {Association for Computing Machinery},
	author = {Lao, An and Shi, Chongyang and Yang, Yayi},
	month = apr,
	year = {2021},
	keywords = {graph aggregation., linear propagation, non-linear propagation, rumor detection},
	pages = {3178--3187},
}

@incollection{hu_residual-duet_2020,
	address = {New York, NY, USA},
	title = {Residual-{Duet} {Network} with {Tree} {Dependency} {Representation} for {Chinese} {Question}-{Answering} {Sentiment} {Analysis}},
	isbn = {978-1-4503-8016-4},
	url = {https://doi.org/10.1145/3397271.3401226},
	abstract = {Question-answering sentiment analysis (QASA) is a novel but meaningful sentiment analysis task based on question-answering online reviews. Existing neural network-based models that conduct sentiment analysis of online reviews have already achieved great success. However, the syntax and implicitly semantic connection in the dependency tree have not been made full use of, especially for Chinese which has specific syntax. In this work, we propose a Residual-Duet Network leveraging textual and tree dependency information for Chinese question-answering sentiment analysis. In particular, we explore the synergies of graph embedding with structural dependency links to learn syntactic information. The transverse and longitudinal compression encoders are developed to capture sentiment evidence with disparate types of compression and different residual connections. We evaluate our model on three Chinese QASA datasets in different domains. Experimental results demonstrate the superiority of our proposed model in Chinese question-answering sentiment analysis.},
	urldate = {2022-01-21},
	booktitle = {Proceedings of the 43rd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Guangyi and Shi, Chongyang and Hao, Shufeng and Bai, Yu},
	month = jul,
	year = {2020},
	keywords = {dependency tree, graph embedding, neural network, sentiment analysis},
	pages = {1725--1728},
}

@article{zhang_hcbc_2019,
	title = {{HCBC}: {A} {Hierarchical} {Case}-{Based} {Classifier} {Integrated} with {Conceptual} {Clustering}},
	volume = {31},
	issn = {1558-2191},
	shorttitle = {{HCBC}},
	doi = {10.1109/TKDE.2018.2824317},
	abstract = {The structured case representation improves case-based reasoning (CBR) by exploring structures in the case base and the relevance of case structures. Recent CBR classifiers have mostly been built upon the attribute-value case representation rather than structured case representation, in which the structural relations embodied in their representation structure are accordingly overlooked in improving the similarity measure. This results in retrieval inefficiency and limitations on the performance of CBR classifiers. This paper proposes a hierarchical case-based classifier, HCBC, which introduces a concept lattice to hierarchically organize cases. By exploiting structural case relations in the concept lattice, a novel dynamic weighting model is proposed to enhance the concept similarity measure. Based on this similarity measure, HCBC retrieves the top-K concepts that are most similar to a new case by using a bottom-up pruning-based recursive retrieval (PRR) algorithm. The concepts extracted in this way are applied to suggest a class label for the case by a weighted majority voting. Experimental results show that HCBC outperforms other classifiers in terms of classification performance and robustness on categorical data, and also works confidently well on numeric datasets. In addition, PRR effectively reduces the search space and greatly improves the retrieval efficiency of HCBC.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhang, Qi and Shi, Chongyang and Niu, Zhendong and Cao, Longbing},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Case-based reasoning, classification, Cognition, concept lattice, hierarchical structure, Indexes, Lattices, Resource management, Semantics, Weight measurement},
	pages = {152--165},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\64850\\Zotero\\storage\\89ZK3GFH\\8333767.html:text/html},
}

@article{feng_context-aware_2021,
	title = {Context-aware item attraction model for session-based recommendation},
	volume = {176},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S095741742100275X},
	doi = {10.1016/j.eswa.2021.114834},
	abstract = {Session-based recommendation uses existing items in users’ interaction sessions to predict the next items with which users will interact. The existing items in sessions usually have different degrees of relevance with each other, and this item relevance also reflects users’ interests. Moreover, when sessions are represented in different structural forms, there will be different types of relevance between items, an aspect typically neglected by previous work. In this paper, we propose a novel Context-aware Item Attraction Model (CIAM) for session-based recommendation, which is capable of capturing different types of relevance between items in order to obtain users’ general and temporal interests and predict the next items in sessions. First, we convert sessions into local and global undirected graphs to mine the item adjacency relevance within and across sessions in order to better determine users’ general interests. Second, we retain the natural sequence structure of sessions, and model the transition relevance between items in sessions to get users’ temporal interests. Third, we design a context-aware item embedding method to obtain the embedding of each item; this method utilizes superposition and a weighted graph convolutional network to aggregate the context information from both the item’s features and the item’s neighborhood. Finally, based on users’ general and temporal interests, as well as the context-aware embeddings of items, we predict the next items with which users will interact during a session. The proposed model is then extensively evaluated on two real-world datasets. Experimental results show that our model outperforms the state-of-the-art baseline methods. Through the analysis of the experiments, we prove that our model can effectively capture the different types of relevance between items within and across sessions for accurately modeling user interests, therefore improving recommendation performance.},
	language = {en},
	urldate = {2022-01-22},
	journal = {Expert Systems with Applications},
	author = {Feng, Chaoqun and Shi, Chongyang and Liu, Chuanming and Zhang, Qi and Hao, Shufeng and Jiang, Xinyu},
	month = aug,
	year = {2021},
	keywords = {Context-aware, Item attraction, Item relevance, Session-based recommendation, Undirected graph},
	pages = {114834},
	file = {ScienceDirect Snapshot:C\:\\Users\\64850\\Zotero\\storage\\6GW68CMY\\S095741742100275X.html:text/html},
}

@article{mohsin_spbc_2021,
	title = {{SPBC}: {A} self-paced learning model for bug classification from historical repositories of open-source software},
	volume = {167},
	issn = {0957-4174},
	shorttitle = {{SPBC}},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417420306230},
	doi = {10.1016/j.eswa.2020.113808},
	abstract = {One of the areas most in need of improvement in the field of automated bug fixing, localization and triaging systems is that of an effective categorization, as this would bugs to reduce the time, cost and effort required to locate, assign and fix the bug. The existing approaches depend upon the textual similarity of the bug description and category in a given reported bug; accordingly, the challenges of unstructured bugs, technical terms, versatile ways of reporting the same bug, the diverse nature and sizes of datasets etc. are often overlooked. Consequently, this limits the classifier performance to a specific type of dataset, resulting in classification inefficiency. To this end, we propose a novel Self-Paced Bug Classifier (SPBC) that is capable of locating the target categories from the bug description of the historical data, maintained by multiple open-source software packages (Bugzilla, Mentis, Redmine). The proposed model introduces a self-paced back-traceable algorithm, controlled by a self-paced regularizer, which classifies textually independent bug descriptions with weighted data-independent tokens (the easy samples). Later on, the regularizer sets comparatively hard samples for textually dependent classification by capturing intra-class and inter-class discrimination features from bug descriptions, based on the weighted similarities of words; this is done with the help of a Key Feature Identification Matrix (KFIM), a Non-Independent and Identically Distributed (NIID) matrix. Easy-to-hard self-pace learning, integrated with textually dependent and independent classification, makes SPBC capable of simultaneously enhancing the effectiveness and robustness of intelligent systems through a substantial increase in precision (5–15\% on average). The main advantage of SPBC is that it targets the spatial relationship between the data and the system, which makes it an apt learner of data and allows it to maintains sample insertion into the classifier at a controlled pace. Additionally, it maintains stability, which is not affected by the dataset’s dimensionality and traits. As is evidenced by the experimental results on four different datasets from open-source projects, our model outperforms the baseline and state-of-the-art methods through a single-stroke solution with improved accuracy and stable performance (average 95\% precision and 4\% decrease in kappa); hence, it is significant for improving intelligent bug fixing and triaging systems.},
	language = {en},
	urldate = {2022-01-22},
	journal = {Expert Systems with Applications},
	author = {Mohsin, Hufsa and Shi, Chongyang},
	month = apr,
	year = {2021},
	keywords = {Bug classification, Bug report analysis, Bug triaging, Defect localization, Self-paced learning},
	pages = {113808},
	file = {ScienceDirect Snapshot:C\:\\Users\\64850\\Zotero\\storage\\U9932SLZ\\S0957417420306230.html:text/html},
}

@inproceedings{meng_dcan_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{DCAN}: {Deep} {Co}-{Attention} {Network} by {Modeling} {User} {Preference} and {News} {Lifecycle} for {News} {Recommendation}},
	isbn = {978-3-030-73200-4},
	shorttitle = {{DCAN}},
	doi = {10.1007/978-3-030-73200-4_7},
	abstract = {Personalized news recommendation systems aim to alleviate information overload and provide users with personalized reading suggestions. In general, each news has its own lifecycle that is depicted by a bell-shaped curve of clicks, which is highly likely to influence users’ choices. However, existing methods typically depend on capturing user preference to make recommendations while ignoring the importance of news lifecycle. To fill this gap, we propose a Deep Co-Attention Network DCAN by modeling user preference and news lifecycle for news recommendation. The core of DCAN is a Co-Attention Net that fuses the user preference attention and news lifecycle attention together to model the dual influence of users’ clicked news. In addition, in order to learn the comprehensive news representation, a Multi-Path CNN is proposed to extract multiple patterns from the news title, content and entities. Moreover, to better capture user preference and model news lifecycle, we present a User Preference LSTM and a News Lifecycle LSTM to extract sequential correlations from news representations and additional features. Extensive experimental results on two real-world news datasets demonstrate the significant superiority of our method and validate the effectiveness of our Co-Attention Net by means of visualization.},
	language = {en},
	booktitle = {Database {Systems} for {Advanced} {Applications}},
	publisher = {Springer International Publishing},
	author = {Meng, Lingkang and Shi, Chongyang and Hao, Shufeng and Su, Xiangrui},
	editor = {Jensen, Christian S. and Lim, Ee-Peng and Yang, De-Nian and Lee, Wang-Chien and Tseng, Vincent S. and Kalogeraki, Vana and Huang, Jen-Wei and Shen, Chih-Ya},
	year = {2021},
	keywords = {Co-attention neural network, Convolutional neural network, News recommendation, Recurrent neural network},
	pages = {100--114},
}

@inproceedings{cao_balanced_2020,
	address = {Barcelona, Spain (Online)},
	title = {Balanced {Joint} {Adversarial} {Training} for {Robust} {Intent} {Detection} and {Slot} {Filling}},
	url = {https://aclanthology.org/2020.coling-main.432},
	doi = {10.18653/v1/2020.coling-main.432},
	abstract = {Joint intent detection and slot filling has recently achieved tremendous success in advancing the performance of utterance understanding. However, many joint models still suffer from the robustness problem, especially on noisy inputs or rare/unseen events. To address this issue, we propose a Joint Adversarial Training (JAT) model to improve the robustness of joint intent detection and slot filling, which consists of two parts: (1) automatically generating joint adversarial examples to attack the joint model, and (2) training the model to defend against the joint adversarial examples so as to robustify the model on small perturbations. As the generated joint adversarial examples have different impacts on the intent detection and slot filling loss, we further propose a Balanced Joint Adversarial Training (BJAT) model that applies a balance factor as a regularization term to the final loss function, which yields a stable training procedure. Extensive experiments and analyses on the lightweight models show that our proposed methods achieve significantly higher scores and substantially improve the robustness of both intent detection and slot filling. In addition, the combination of our BJAT with BERT-large achieves state-of-the-art results on two datasets.},
	urldate = {2022-01-22},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Cao, Xu and Xiong, Deyi and Shi, Chongyang and Wang, Chao and Meng, Yao and Hu, Changjian},
	month = dec,
	year = {2020},
	pages = {4926--4936},
	file = {Full Text PDF:C\:\\Users\\64850\\Zotero\\storage\\HQSYJY7M\\Cao 等。 - 2020 - Balanced Joint Adversarial Training for Robust Int.pdf:application/pdf},
}

@article{hao_modeling_2019,
	title = {Modeling positive and negative feedback for improving document retrieval},
	volume = {120},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417418307553},
	doi = {10.1016/j.eswa.2018.11.035},
	abstract = {Pseudo-relevance feedback (PRF) has evident potential for enriching the representation of short queries. Traditional PRF methods treat top-ranked documents as feedback, since they are assumed to be relevant to the query. However, some of these feedback documents may actually distract from the query topic for a range of reasons and accordingly downgrade PRF system performance. Such documents constitute negative examples (negative feedback) but could also be valuable in retrieval. In this paper, a novel framework of query language model construction is proposed in order to improve retrieval performance by integrating both positive and negative feedback. First, an improvement-based method is proposed to automatically identify the types of feedback documents (i.e. positive or negative) according to whether the document enhances the retrieval’s effectiveness. Subsequently, based on the learned positive and negative examples, the positive feedback models and the negative feedback models are estimated using an Expectation-Maximization algorithm with the assumptions: the positive term distribution is affected by the context term distribution and the negative term distribution is affected by both the positive term distribution and the context term distribution (such that the positive feedback model upgrades the rankings of relevant documents and the negative feedback model prunes the irrelevant documents from a query). Finally, a content-based representativeness criterion is proposed in order to obtain the representative negative feedback documents. Experiments conducted on the TREC collections demonstrate that our proposed approach results in better retrieval accuracy and robustness than baseline methods.},
	language = {en},
	urldate = {2022-01-22},
	journal = {Expert Systems with Applications},
	author = {Hao, Shufeng and Shi, Chongyang and Niu, Zhendong and Cao, Longbing},
	month = apr,
	year = {2019},
	keywords = {Language model, Negative feedback, Positive feedback, Pseudo-relevance feedback},
	pages = {253--261},
	file = {ScienceDirect Snapshot:C\:\\Users\\64850\\Zotero\\storage\\45IT6EMG\\S0957417418307553.html:text/html},
}

@article{hao_concept_2018,
	title = {Concept coupling learning for improving concept lattice-based document retrieval},
	volume = {69},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197617303020},
	doi = {10.1016/j.engappai.2017.12.007},
	abstract = {The semantic information in any document collection is critical for query understanding in information retrieval. Existing concept lattice-based retrieval systems mainly rely on the partial order relation of formal concepts to index documents. However, the methods used by these systems often ignore the explicit semantic information between the formal concepts extracted from the collection. In this paper, a concept coupling relationship analysis model is proposed to learn and aggregate the intra- and inter-concept coupling relationships. The intra-concept coupling relationship employs the common terms of formal concepts to describe the explicit semantics of formal concepts. The inter-concept coupling relationship adopts the partial order relation of formal concepts to capture the implicit dependency of formal concepts. Based on the concept coupling relationship analysis model, we propose a concept lattice-based retrieval framework. This framework represents user queries and documents in a concept space based on fuzzy formal concept analysis, utilizes a concept lattice as a semantic index to organize documents, and ranks documents with respect to the learned concept coupling relationships. Experiments are performed on the text collections acquired from the SMART information retrieval system. Compared with classic concept lattice-based retrieval methods, our proposed method achieves at least 9\%, 8\% and 15\% improvement in terms of average MAP, IAP@11 and P@10 respectively on all the collections.},
	language = {en},
	urldate = {2022-01-22},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Hao, Shufeng and Shi, Chongyang and Niu, Zhendong and Cao, Longbing},
	month = mar,
	year = {2018},
	keywords = {Coupling relationship, Fuzzy formal concept analysis, Lattice-based document retrieval},
	pages = {65--75},
	file = {ScienceDirect Snapshot:C\:\\Users\\64850\\Zotero\\storage\\VQ63VIH8\\S0952197617303020.html:text/html;已提交版本:C\:\\Users\\64850\\Zotero\\storage\\KQN8QBJ3\\Hao 等。 - 2018 - Concept coupling learning for improving concept la.pdf:application/pdf},
}

@article{zhang_case-based_2016,
	title = {Case-{Based} {Classification} on {Hierarchical} {Structure} of {Formal} {Concept} {Analysis}},
	url = {https://ebooks.iospress.nl/doi/10.3233/978-1-61499-672-9-1758},
	doi = {10.3233/978-1-61499-672-9-1758},
	urldate = {2022-01-22},
	journal = {ECAI 2016},
	author = {Zhang, Qi and Shi, Chongyang and Sun, Ping and Niu, Zhengdong},
	year = {2016},
	note = {Publisher: IOS Press},
	pages = {1758--1759},
	file = {Full Text PDF:C\:\\Users\\64850\\Zotero\\storage\\U269KL3C\\Zhang 等。 - 2016 - Case-Based Classification on Hierarchical Structur.pdf:application/pdf;Snapshot:C\:\\Users\\64850\\Zotero\\storage\\LBW7QFCE\\978-1-61499-672-9-1758.html:text/html},
}

@inproceedings{zhang_exploiting_2020,
	title = {Exploiting {BERT} with {Global}-{Local} {Context} and {Label} {Dependency} for {Aspect} {Term} {Extraction}},
	doi = {10.1109/DSAA49011.2020.00049},
	abstract = {Aspect term extraction (ATE) is a subtask of aspect-based sentiment analysis (ABSA), which aims to extract all aspect-specific words in a sentence. Recent neural network methods ignore the problem that word may play different semantic roles in different sentences and have limitation in handling dependencies between labels. In this work, we first exploit BERT as embedding layer to obtain word-level representations and utilize BERT architecture to capture global sequence features. Then, a position-aware attention is proposed to extract local context information. Global-local context representations of words are built by merging the global sequence features and local context information, which can select related information from both sides: global sequence and local context. Finally, to model the label dependency, we construct a label dependency module based on RNN and CRF, where the previous label features are introduced as additional information for label relationship modeling. Experimental results on four benchmark datasets show that our proposed model obtains the state-of-the-art performance.},
	booktitle = {2020 {IEEE} 7th {International} {Conference} on {Data} {Science} and {Advanced} {Analytics} ({DSAA})},
	author = {Zhang, Qingxuan and Shi, Chongyang},
	month = oct,
	year = {2020},
	keywords = {Aspect Term Extraction, Bit error rate, Context modeling, Feature extraction, Global-Local Context, Hidden Markov models, Label Dependency, Neural networks, Predictive models, Task analysis},
	pages = {354--362},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\64850\\Zotero\\storage\\VSRQ6CHI\\9260073.html:text/html},
}

@inproceedings{zhang_attentive_2019,
	title = {An {Attentive} {Memory} {Network} {Integrated} with {Aspect} {Dependency} for {Document}-{Level} {Multi}-{Aspect} {Sentiment} {Classification}},
	url = {https://proceedings.mlr.press/v101/zhang19b.html},
	abstract = {Document-level multi-aspect sentiment classification is one of the foundational tasks in natural language processing (NLP) and neural network methods have achieved great success in reviews sentiment classification. Most of recent works ignore the relation between different aspects and do not take into account the contexting dependent importance of sentences and aspect keywords. In this paper, we propose an attentive memory network for document-level multi-aspect sentiment classification. Unlike recent proposed models which average word embeddings of aspect keywords to represent aspect and utilize hierarchical architectures to encode review documents, we adopt attention-based memory networks to construct aspect and sentence memories. The recurrent attention operation is employed to capture long-distance dependency across sentences and obtain aspect-aware document representations over aspect and sentence memories. Then, incorporating the neighboring aspects related information into the final aspect rating predictions by using multi-hop attention memory networks. Experimental results on two real-world datasets TripAdvisor and BeerAdvocate show that our model achieves state-of-the-art performance.},
	language = {en},
	urldate = {2022-01-22},
	booktitle = {Proceedings of {The} {Eleventh} {Asian} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Zhang, Qingxuan and Shi, Chongyang},
	month = oct,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {425--440},
	file = {Full Text PDF:C\:\\Users\\64850\\Zotero\\storage\\6EE2YBF6\\Zhang 和 Shi - 2019 - An Attentive Memory Network Integrated with Aspect.pdf:application/pdf},
}

@article{yu_query_2019,
	title = {Query {Expansion} {Based} on {Formal} {Concept} {Analysis} {From} {Retrieved} {Documents}},
	volume = {20},
	copyright = {Copyright (c) 2019 Journal of Internet Technology},
	issn = {2079-4029},
	url = {https://jit.ndhu.edu.tw/article/view/2015},
	abstract = {In this paper, we propose a new formal concept analysis (FCA)-based query expansion approach, which uses the set of retrieved document collection against the whole document set. In this approach, description topics (DTs) are extracted from the documents and organized to denote precisely the user’s information need. For a new query, we build a concept lattice from the extracted DTs, using the retrieved document collection as the formal context, and choose the most probable interpretations as query concepts. Our experiments are performed on two collections (data sets from TREC-7, TREC-8 and AP89). The experimental evaluation shows that our approach can reduce the overall computational overhead, and is as good as some typical query expansion approaches.},
	language = {en-US},
	number = {2},
	urldate = {2022-01-22},
	journal = {Journal of Internet Technology},
	author = {Yu, Haibin and Shi, Chongyang and Bai, Yu and Zhang, Chunxia and Hearne, Ryan},
	month = mar,
	year = {2019},
	note = {Number: 2},
	pages = {409--421},
	file = {Full Text PDF:C\:\\Users\\64850\\Zotero\\storage\\KJEHB6P4\\Yu 等。 - 2019 - Query Expansion Based on Formal Concept Analysis F.pdf:application/pdf},
}

@article{yu_new_2018,
	title = {A {New} {Digital} {Paper} {Search} {Paradigm} {Based} on {FCA}},
	volume = {19},
	copyright = {Copyright (c) 2018 Journal of Internet Technology},
	issn = {2079-4029},
	url = {https://jit.ndhu.edu.tw/article/view/1728},
	abstract = {This paper proposes a new digital paper search paradigm that controls the diversity of keyword-based search query topics based on Formal Concept Analysis (FCA). During pre-querying, papers are assigned to pre-specified, lattice-based context patterns built by a selected partial dataset, and query-independent lattice context scores are attached to papers with respect to the assigned lattice contexts. When a query is executed, the relevant lattice contexts are selected, a search is performed within the selected lattice contexts, the context scores of the papers are revised to become relevancy scores with respect to the query and the lattice context they are in, and the query outputs are ranked within each relevant lattice context. In this way, we (1) provide FCA with a path to deal with middling or larger amounts of documents, (2) minimize query output topic diversity and reduce query output size, (3) decrease the user’s time spent scanning query results, and (4) increase query output ranking accuracy. Using China National Knowledge Infrastructure (CNKI) publications as the testbed, our experiments indicate that the proposed lattice context-based search approach produces search results with up to 50\% higher precision, and reduces the query output size by up to 60\% more than a CNKI search.},
	language = {en-US},
	number = {4},
	urldate = {2022-01-22},
	journal = {Journal of Internet Technology},
	author = {Yu, Haibin and Shi, Chongyang and Yu, Bai and Zhang, Chunxia and Hearne, Ryan},
	month = jul,
	year = {2018},
	note = {Number: 4},
	pages = {1099--1110},
	file = {Full Text PDF:C\:\\Users\\64850\\Zotero\\storage\\U542NB2G\\Yu 等。 - 2018 - A New Digital Paper Search Paradigm Based on FCA.pdf:application/pdf},
}

@article{shi_case_2016,
	title = {Case {Retrieval} {Based} on {Formal} {Concept} {Analysis}},
	volume = {13},
	doi = {10.1166/jctn.2016.5271},
	abstract = {This paper proposes a novel case-based retrieval measure by using formal concept analysis. The proposed method employs the concept lattice to express the knowledge base of cases. The proposed retrieval method combines semantic, featural, and structural information into a decision. In
this measure, we use the information content approach to obtain automatically the semantic part of the similarity scores of two concepts that constitute the traditional feature and structural similarity-evaluating measures. Furthermore, the similarity for case retrieval can be calculated from
the lower approximations on the basis of the rough set. Experiment results on the four UCI datasets show that our proposed similarity measure provides better accuracy than some existing similarity measures.},
	number = {7},
	journal = {Journal of Computational and Theoretical Nanoscience},
	author = {Shi, Chongyang and Yu, Bai and Niu, Zhendong and Qi, Zhang},
	month = jul,
	year = {2016},
	keywords = {Case-Based Reasoning, Formal Concept Analysis, Information Content Similarity, Rough Set},
	pages = {4211--4222},
}

@inproceedings{shi_similarity_2016,
	title = {Similarity model based on {CBR} and {FCA}},
	doi = {10.1109/SNPD.2016.7515965},
	abstract = {Case-based reasoning (CBR) is one of the research highlights in the artificial intelligence field. In the process of case retrieval of CBR, Similarity is an important index in evaluation. This paper proposed a new model calculating similarity between source case and target case. The model is suitable for using Formal Concept Analysis (FCA) in the case of CBR. The model considered the case attributes weights between two formal concepts and feature attributes weights in concept lattices. Comparing to the similarity model put forward by Jirapond Tadrat, this model cut down the comparison to the objects, weight more in the attributes and shorten the time of solving the similarity. Theoretical deduction proves that the proposed similarity model satisfy the basic conditions which all these models need to meet. This article chose the UCI data sets and the method of cross validation, carried on an experiment from both similarity model aspect and classifier aspect respectively. The former experimental results show that the similarity model has higher accuracy than others. The latter experimental results show that the similarity model of CBR classifier has higher accuracy in the attribute set density compared with other small data set classifier.},
	booktitle = {2016 17th {IEEE}/{ACIS} {International} {Conference} on {Software} {Engineering}, {Artificial} {Intelligence}, {Networking} and {Parallel}/{Distributed} {Computing} ({SNPD})},
	author = {Shi, Chongyang and Lai, Linjing and Fan, Jing and Bai, Yu},
	month = may,
	year = {2016},
	keywords = {Analytical models, Case library, Case-based reasoning, Cognition, Computational modeling, Concept lattice, Context, Formal concept analysis, Lattices, Libraries},
	pages = {597--603},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\64850\\Zotero\\storage\\LC6CDUWX\\7515965.html:text/html},
}

@article{__2015,
	title = {基于分类模型的查询扩展方法},
	volume = {42},
	issn = {1002-137X},
	url = {https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2015&filename=JSJA201506005&uniplatform=NZKPT&v=aKmfxZhtcT9qkzR8JkUnEsU--ncAFENM0JmK4l0GkLHnPkzgSNV9RmOj5tSq2ChH},
	abstract = {查询扩展作为查询优化的重要组成部分,对改善信息检索系统的性能起到了至关重要的作用。传统的伪相关反馈查询扩展方法虽然在一定程度上提高了检索性能,但选择的扩展词中会包含一部分与原查询不相关的词语,这对检索性能的提升产生了不利影响。提出了一种基于分类模型的查询扩展方法,该算法综合候选扩展词的统计信息和多种特征,采用朴素贝叶斯分类模型对初次得到的候选扩展词进行再次分类选择,进一步去除与查询词相关性小的扩展词。在TREC 2013数据集上的实验结果表明,提出的查询扩展方法能够有效提高用户查询的查准率和查全率。},
	language = {中文;},
	number = {06},
	urldate = {2022-01-22},
	journal = {计算机科学},
	author = {李, 维银 and 石, 玉龙 and 陈, 杰 and 施, 重阳},
	year = {2015},
	note = {11 citations(CNKI)[2022-1-22]{\textless}北大核心, CSCD{\textgreater}},
	keywords = {查询扩展, 分类模型, 伪相关反馈, 信息检索, Classification model, Information retrieval, Pseudo relevance feedback, Query expansion},
	pages = {18--22},
}

@article{zhao_hybrid_2015,
	title = {A hybrid approach of topic model and matrix factorization based on two-step recommendation framework},
	volume = {44},
	issn = {1573-7675},
	url = {https://doi.org/10.1007/s10844-014-0334-3},
	doi = {10.1007/s10844-014-0334-3},
	abstract = {Recommender systems become increasingly significant in solving the information explosion problem. Two typical kinds of techniques treat the recommendation problem as either a rating prediction or a ranking prediction one. In contrast, we propose a two-step framework that considers recommendation as a simulation of users’ behaviors to generate ratings. The first step is to predict the probability that a user rates an item, and the second step is to predict rating values. After that, the predicted results from both steps are combined to compute the expectations of users’ ratings on items, which are used to generate recommendations. Based on this framework, we propose a hybrid approach which uses topic model in the first step and matrix factorization in the second to solve the recommendation problem. Experiments with MovieLens and EachMovie datasets demonstrate the effectiveness of the proposed framework and the recommendation approach.},
	language = {en},
	number = {3},
	urldate = {2022-01-22},
	journal = {Journal of Intelligent Information Systems},
	author = {Zhao, Xiangyu and Niu, Zhendong and Chen, Wei and Shi, Chongyang and Niu, Ke and Liu, Donglei},
	month = jun,
	year = {2015},
	pages = {335--353},
}

@article{huang_automatic_2014,
	title = {Automatic construction of domain-specific sentiment lexicon based on constrained label propagation},
	volume = {56},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705113003596},
	doi = {10.1016/j.knosys.2013.11.009},
	abstract = {Domain-specific sentiment lexicon has played an important role in most practical opinion mining systems. Due to the ubiquitous domain diversity and absence of domain-specific prior knowledge, automatic construction of domain-specific sentiment lexicon has become a challenging research topic in recent years. This paper proposes a novel automatic construction strategy of domain-specific sentiment lexicon based on constrained label propagation. The candidate sentiment terms are extracted by leveraging the chunk dependency information and prior generic lexicon. The pairwise contextual and morphological constraints are defined and extracted between sentiment terms from the domain corpus, and are exploited as prior knowledge to improve the sentiment lexicon construction. The constraint propagation is applied to spread the effect of local constraints throughout the entire collection of candidate sentiment terms. The final propagated constraints are incorporated into the label propagation for the domain-specific sentiment lexicon construction. Experimental results on real-life datasets demonstrate that our approach to constrained label propagation could dramatically improve the performance of automatic construction of domain-specific sentiment lexicon.},
	language = {en},
	urldate = {2022-01-22},
	journal = {Knowledge-Based Systems},
	author = {Huang, Sheng and Niu, Zhendong and Shi, Chongyang},
	month = jan,
	year = {2014},
	keywords = {Automatic construction, Constrained label propagation, Constraint propagation, Domain-specific sentiment lexicon, Opinion mining},
	pages = {191--200},
}

@inproceedings{li_agent-based_2014,
	title = {An agent-based linked data integration system},
	doi = {10.1109/ICADIWT.2014.6814676},
	abstract = {With the advent of the Web of Linked Data, new challenges to federated query processing are emerging. Different from traditional federated database systems which do static data integration, this Web of Data is open and ever-changing. In this paper, we present a agent-based architecture providing a flexible and decoupled solution for the federated queries over Linked Data. Based on the presented architecture, a Linked Data Management System (LDMS) has been developed. LDMS manages Linked Data in a virtual way, i.e., it does not load remote data into a local data store. With an application scenario, we demonstrate the scalability and extensibility of the presented architecture.},
	booktitle = {The {Fifth} {International} {Conference} on the {Applications} of {Digital} {Information} and {Web} {Technologies} ({ICADIWT} 2014)},
	author = {Li, Xuejin and Niu, Zhendong and Shi, Chongyang},
	month = feb,
	year = {2014},
	keywords = {Computer architecture, Data integration, Data models, Educational institutions, Java, Monitoring, Query processing},
	pages = {113--117},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\64850\\Zotero\\storage\\GA997E2G\\6814676.html:text/html},
}

@inproceedings{zhang_representation_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Representation and {Verification} of {Attribute} {Knowledge}},
	isbn = {978-3-642-39787-5},
	doi = {10.1007/978-3-642-39787-5_39},
	abstract = {With the increasing growth and popularization of the Internet, knowledge extraction from the web is an important issue in the fields of web mining, ontology engineering and intelligent information processing. The availability of real big corpora and the development of technologies of internet network and machine learning make it feasible to acquire massive knowledge from the web. In addition, many web-based encyclopedias such as Wikipedia and Baidu Baike include much structured knowledge. However, knowledge qualities including the incorrectness, inconsistency, and incompleteness become a serious obstacle for the wide practical applications of those extracted and structured knowledge. In this paper, we build a taxonomy of relations between attributes of concepts, and propose a taxonomy of attribute relations driven approach to evaluating the knowledge about attribute values of attributes of entities. We also address an application of our approach to building and verifying attribute knowledge of entities in different domains.},
	language = {en},
	booktitle = {Knowledge {Science}, {Engineering} and {Management}},
	publisher = {Springer},
	author = {Zhang, Chunxia and Niu, Zhendong and Shi, Chongyang and Tan, Mengdi and Fu, Hongping and Xu, Sheng},
	editor = {Wang, Mingzheng},
	year = {2013},
	keywords = {attribute values, knowledge verification, ontology verification, Taxonomy of attribute relations},
	pages = {473--482},
}
